{
    "model_type": "llm",
    "global_batch_size": 1,
    "input_seqlen": 4096,
    "output_seqlen": 512,
    "decode_width": 1,
    "d_model": 5120,
    "num_heads": 40,
    "d_head": 128,
    "d_ff": 13824,
    "num_layers": 40,
    "ffn_type": "llama",

    "data_parallelism_degree": 1,
    "tensor_parallelism_degree": 1,
    "pipeline_parallelism_degree": 1,
    "num_data_parallel_axes": 0,
    "num_tensor_parallel_axes": 0,
    "num_pipeline_parallel_axes": 0,
    "data_parallel_degree_dcn": 1,
    "tensor_parallel_degree_dcn": 1,
    "pipeline_parallel_degree_dcn": 1,
    "microbatch_size_dcn": 1,
    "microbatch_size_ici": 1,
    "num_chips": 1,
    "output_file_path": "v2.csv"
}
